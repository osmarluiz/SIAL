{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning for Sparse Semantic Segmentation\n",
    "\n",
    "This notebook provides a simple workflow for training semantic segmentation models using sparse point annotations through active learning.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "**One-Time Setup:**\n",
    "1. **Cell 1**: Setup and Imports\n",
    "2. **Cell 2**: Configure Dataset + Model\n",
    "3. **Cell 3**: Create/Load Session\n",
    "\n",
    "**Active Learning Loop:**\n",
    "4. **Cell 4**: Annotate (launch tool, add/edit points)\n",
    "5. **Cell 5**: Train (train model, generate predictions, create next iteration)\n",
    "6. **Repeat**: Cell 4 â†’ Cell 5 â†’ Cell 4 â†’ Cell 5...\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- PyTorch 1.10+\n",
    "- segmentation_models_pytorch\n",
    "- PyQt5 (for annotation tool)\n",
    "- See `requirements.txt` for full dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 1: Setup and Imports\n",
    "\n",
    "Import required libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ PyTorch 2.6.0+cu126 available\n",
      "âœ“ CUDA available: True\n",
      "âœ“ CUDA device: NVIDIA GeForce RTX 4090\n",
      "âœ“ segmentation_models_pytorch available\n",
      "\n",
      "âœ“ All imports successful\n",
      "âœ“ Project root: d:\\SIAL\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project modules\n",
    "from src.utils.config_loader import load_dataset_config, load_training_config\n",
    "from src.session.mask_utils import batch_json_to_masks\n",
    "from src.session.simple_mask_converter import convert_mask_to_json\n",
    "\n",
    "# Check PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.utils.data as data\n",
    "    from torchvision import transforms\n",
    "    print(f\"âœ“ PyTorch {torch.__version__} available\")\n",
    "    print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"âœ“ CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"âœ— PyTorch not found. Install with: conda install pytorch torchvision cudatoolkit -c pytorch\")\n",
    "    raise\n",
    "\n",
    "# Check segmentation_models_pytorch\n",
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "    print(f\"âœ“ segmentation_models_pytorch available\")\n",
    "except ImportError:\n",
    "    print(\"âœ— segmentation_models_pytorch not found. Install with: pip install segmentation-models-pytorch\")\n",
    "    raise\n",
    "\n",
    "# Set matplotlib style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"\\nâœ“ All imports successful\")\n",
    "print(f\"âœ“ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 2: Configure Dataset + Model\n",
    "\n",
    "Load configurations and create model, loss, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configurations...\n",
      "\n",
      "Dataset: VAIHINGEN_1K_V3\n",
      "  Classes: 6\n",
      "  Class names: impervious, building, tree, car, low_veg, clutter\n",
      "  Image size: 512x512\n",
      "  Ignore index: 6\n",
      "\n",
      "Training: UNet-EfficientNetB7\n",
      "  Model: Unet\n",
      "  Encoder: efficientnet-b7\n",
      "  Epochs: 500\n",
      "  Batch size: train=10, val=50\n",
      "  Device: cuda\n",
      "  Learning rate: 0.0001\n",
      "\n",
      "Setting up training components...\n",
      "âœ“ Model: Unet + efficientnet-b7\n",
      "âœ“ Device: cuda\n",
      "âœ“ Train Loss: DWCDL (confident_wrong=10.0x, uncertain_wrong=4.0x, uncertain_correct=2.0x)\n",
      "âœ“ Val Loss: CrossEntropyLoss\n",
      "âœ“ Metrics: mIoU\n",
      "âœ“ Optimizer: Adam (lr=0.0001)\n",
      "âœ“ Training setup complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration paths\n",
    "DATASET_CONFIG_PATH = 'configs/datasets/vaihingen_1k_v3.yaml'\n",
    "TRAINING_CONFIG_PATH = 'configs/training/unet_efficientnet_b7.yaml'\n",
    "\n",
    "# Load configurations\n",
    "print(\"Loading configurations...\\n\")\n",
    "\n",
    "dataset_config = load_dataset_config(DATASET_CONFIG_PATH)\n",
    "print(f\"Dataset: {dataset_config['name']}\")\n",
    "print(f\"  Classes: {dataset_config['classes']['num_classes']}\")\n",
    "print(f\"  Class names: {', '.join(dataset_config['classes']['names'])}\")\n",
    "print(f\"  Image size: {dataset_config['image']['width']}x{dataset_config['image']['height']}\")\n",
    "print(f\"  Ignore index: {dataset_config['classes']['ignore_index']}\")\n",
    "\n",
    "training_config = load_training_config(TRAINING_CONFIG_PATH)\n",
    "print(f\"\\nTraining: {training_config['name']}\")\n",
    "print(f\"  Model: {training_config['model']['architecture']}\")\n",
    "print(f\"  Encoder: {training_config['model']['encoder']}\")\n",
    "print(f\"  Epochs: {training_config['training']['num_epochs']}\")\n",
    "print(f\"  Batch size: train={training_config['training']['batch_size']['train']}, val={training_config['training']['batch_size']['val']}\")\n",
    "print(f\"  Device: {training_config['training']['device']}\")\n",
    "print(f\"  Learning rate: {training_config['optimizer']['params']['lr']}\")\n",
    "\n",
    "# Setup training (model, losses, metrics, optimizer)\n",
    "print()\n",
    "from src.training.setup import setup_training\n",
    "\n",
    "model, device, train_loss, val_loss, metrics, optimizer = setup_training(\n",
    "    dataset_config=dataset_config,\n",
    "    training_config=training_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 3: Create/Load Session\n",
    "\n",
    "Create a new session or load an existing one.\n",
    "\n",
    "**Session Structure:**\n",
    "```\n",
    "Sessions/\n",
    "  â””â”€â”€ {SESSION_NAME}/\n",
    "      â”œâ”€â”€ iteration_0/\n",
    "      â”‚   â”œâ”€â”€ annotations/  # JSON files\n",
    "      â”‚   â”œâ”€â”€ masks/        # PNG masks\n",
    "      â”‚   â”œâ”€â”€ models/       # Model weights\n",
    "      â”‚   â””â”€â”€ predictions/  # Predictions\n",
    "      â”œâ”€â”€ iteration_1/\n",
    "      â”‚   â””â”€â”€ ...\n",
    "      â””â”€â”€ metrics_history.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session: VAIHINGEN_1k\n",
      "Path: Sessions\\VAIHINGEN_1k\n",
      "\n",
      "Loading existing session...\n",
      "\n",
      "Available iterations: [0, 1, 2, 3, 4]\n",
      "Latest iteration: 4\n",
      "\n",
      "Iteration 4 status:\n",
      "  Annotations: âœ“ (1000 files)\n",
      "  Masks:       âœ“ (1000 files)\n",
      "  Model:       âœ—\n",
      "  Predictions: âœ— (0 files)\n",
      "\n",
      "Metrics history:\n",
      " iteration     miou  pixel_accuracy  train_loss  val_loss\n",
      "         0 0.501606        0.792913    0.469387  1.258772\n",
      "         1 0.562324        0.836759    0.555166  1.217716\n",
      "         2 0.584286        0.844113    0.590927  1.198189\n",
      "         3 0.602103        0.855051    0.605222  1.195125\n",
      "\n",
      "âœ“ Session loaded: Sessions\\VAIHINGEN_1k\n",
      "\n",
      "============================================================\n",
      "SESSION READY\n",
      "============================================================\n",
      "â†’ Run Cell 4 to annotate\n",
      "â†’ Run Cell 5 to train\n"
     ]
    }
   ],
   "source": [
    "# Session configuration\n",
    "SESSION_NAME = 'VAIHINGEN_1k'\n",
    "SESSION_PATH = Path(f'Sessions/{SESSION_NAME}')\n",
    "LAUNCH_TOOL = True\n",
    "\n",
    "print(f\"Session: {SESSION_NAME}\")\n",
    "print(f\"Path: {SESSION_PATH}\\n\")\n",
    "\n",
    "# Get or create session (modularized!)\n",
    "from src.session.manager import get_or_create_session\n",
    "\n",
    "session_info = get_or_create_session(\n",
    "    session_path=SESSION_PATH,\n",
    "    dataset_config=dataset_config\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SESSION READY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"â†’ Run Cell 4 to annotate\")\n",
    "print(f\"â†’ Run Cell 5 to train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 4: Annotate ðŸŽ¨\n",
    "\n",
    "Launch the annotation tool to add or refine point annotations.\n",
    "\n",
    "**What happens:**\n",
    "1. Finds latest iteration\n",
    "2. Launches VIZ_SOFTWARE annotation tool (PyQt5 window)\n",
    "3. Shows images with current annotations\n",
    "4. Shows predictions from previous iteration (if available)\n",
    "5. You add/edit/remove annotation points\n",
    "6. Tool auto-saves to JSONs\n",
    "7. When you close the tool:\n",
    "   - Converts JSONs â†’ PNG masks\n",
    "   - Ready for training\n",
    "\n",
    "**After this cell:**\n",
    "- Run Cell 5 to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANNOTATION WORKFLOW\n",
      "============================================================\n",
      "\n",
      "Iteration: 4\n",
      "Session: Sessions\\VAIHINGEN_1k\n",
      "\n",
      "Current status:\n",
      "  Annotations: 1000 files\n",
      "  Masks:       1000 files\n",
      "  Predictions: 1000 files (from iteration 3)\n",
      "\n",
      "âœ“ Predictions available - will guide your annotations\n",
      "\n",
      "------------------------------------------------------------\n",
      "LAUNCHING ANNOTATION TOOL...\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "============================================================\n",
      "âœ“ ANNOTATION TOOL CLOSED\n",
      "============================================================\n",
      "\n",
      "Converting annotations to masks...\n",
      "\n",
      "âœ“ Converted 1000 annotations to masks\n",
      "\n",
      "============================================================\n",
      "ANNOTATION COMPLETE\n",
      "============================================================\n",
      "â†’ Run Cell 5 to train model\n"
     ]
    }
   ],
   "source": [
    "# Annotation workflow configuration\n",
    "LAUNCH_TOOL = True  # Set to False to skip annotation tool\n",
    "\n",
    "# Run annotation workflow (modularized!)\n",
    "from src.annotation.launcher import run_annotation_workflow\n",
    "\n",
    "result = run_annotation_workflow(\n",
    "    session_path=SESSION_PATH,\n",
    "    dataset_config=dataset_config,\n",
    "    iteration='latest',  # or 'current', or specific iteration number (0, 1, 2, ...)\n",
    "    launch_tool=LAUNCH_TOOL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cell 5: Train ðŸš€\n",
    "\n",
    "Train the model on annotated data.\n",
    "\n",
    "**What happens:**\n",
    "1. Finds latest iteration\n",
    "2. Loads masks from `iteration_N/masks/`\n",
    "3. Trains model (simple training using smp)\n",
    "4. Saves best model to `iteration_N/models/best_model.pth`\n",
    "5. Generates predictions â†’ `iteration_N/predictions/`\n",
    "6. Creates next iteration (`iteration_{N+1}`)\n",
    "7. Copies annotations to next iteration\n",
    "\n",
    "**After this cell:**\n",
    "- Go back to Cell 4 to annotate the next iteration\n",
    "- The loop continues: Cell 4 â†’ Cell 5 â†’ Cell 4 â†’ Cell 5..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "VISUALIZE = False  # Set to False to skip visualization plots\n",
    "\n",
    "# Run training iteration (modularized!)\n",
    "from src.training.workflow import run_training_iteration\n",
    "\n",
    "result = run_training_iteration(\n",
    "    session_path=SESSION_PATH,\n",
    "    dataset_config=dataset_config,\n",
    "    training_config=training_config,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    train_loss=train_loss,\n",
    "    val_loss=val_loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    iteration='latest',  # or 'current', or specific iteration number (0, 1, 2, ...)\n",
    "    visualize=VISUALIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
